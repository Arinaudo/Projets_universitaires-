{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "641d5d76-1b47-4047-b8a7-d57122491ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importation des bibliothèques \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "import pandas as pd\n",
    "import os \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7f9cdfa-c95d-4da6-9505-e4e013374735",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Année 2024: 275\n",
      "Année 2023: 327\n",
      "Année 2022: 336\n",
      "Année 2021: 324\n",
      "Année 2020: 288\n",
      "Année 2019: 285\n",
      "Année 2018: 268\n",
      "Année 2017: 269\n",
      "Année 2016: 278\n",
      "Année 2015: 275\n",
      "Année 2014: 268\n",
      "Année 2013: 188\n",
      "Année 2012: 122\n"
     ]
    }
   ],
   "source": [
    "#acquisition des tableaux pour l'extraction des données et préparation des listes pour le scrapping \n",
    "SB2024_top2000 = pd.read_excel(\"C:/Users/alexi/OneDrive/Bureau/Fac/Master/Mémoire/Analyse de données/Excel commission européenne/SB2024.xlsx\", engine=\"openpyxl\")\n",
    "SB2023_World2500=pd.read_excel(\"C:/Users/alexi/OneDrive/Bureau/Fac/Master/Mémoire/Analyse de données/Excel commission européenne/SB2023.xlsx\", engine=\"openpyxl\")\n",
    "SB2022_World2500=pd.read_excel(\"C:/Users/alexi/OneDrive/Bureau/Fac/Master/Mémoire/Analyse de données/Excel commission européenne/SB2022.xlsx\", engine=\"openpyxl\")\n",
    "SB2021_World2500=pd.read_excel(\"C:/Users/alexi/OneDrive/Bureau/Fac/Master/Mémoire/Analyse de données/Excel commission européenne/SB2021.xlsx\", engine=\"openpyxl\")\n",
    "SB2020_World2500=pd.read_excel(\"C:/Users/alexi/OneDrive/Bureau/Fac/Master/Mémoire/Analyse de données/Excel commission européenne/SB2020.xlsx\", engine=\"openpyxl\")\n",
    "SB2019_top2500=pd.read_excel(\"C:/Users/alexi/OneDrive/Bureau/Fac/Master/Mémoire/Analyse de données/Excel commission européenne/SB2019.xlsx\", engine=\"openpyxl\")\n",
    "SB2018_top2500=pd.read_excel(\"C:/Users/alexi/OneDrive/Bureau/Fac/Master/Mémoire/Analyse de données/Excel commission européenne/SB2018.xlsx\", engine=\"openpyxl\")\n",
    "SB2017_top2500=pd.read_excel(\"C:/Users/alexi/OneDrive/Bureau/Fac/Master/Mémoire/Analyse de données/Excel commission européenne/SB2017.xlsx\", engine=\"openpyxl\")\n",
    "SB2016_top2500=pd.read_excel(\"C:/Users/alexi/OneDrive/Bureau/Fac/Master/Mémoire/Analyse de données/Excel commission européenne/SB2016.xlsx\", engine=\"openpyxl\")\n",
    "SB2015_top2500=pd.read_excel(\"C:/Users/alexi/OneDrive/Bureau/Fac/Master/Mémoire/Analyse de données/Excel commission européenne/SB2015.xlsx\", engine=\"openpyxl\")\n",
    "SB2014_top2500=pd.read_excel(\"C:/Users/alexi/OneDrive/Bureau/Fac/Master/Mémoire/Analyse de données/Excel commission européenne/SB2014.xlsx\", engine=\"openpyxl\")\n",
    "SB2013_top2000=pd.read_excel(\"C:/Users/alexi/OneDrive/Bureau/Fac/Master/Mémoire/Analyse de données/Excel commission européenne/SB2013.xlsx\", engine=\"openpyxl\")\n",
    "SB2012_top1500=pd.read_excel(\"C:/Users/alexi/OneDrive/Bureau/Fac/Master/Mémoire/Analyse de données/Excel commission européenne/SB2012.xls\", engine=\"xlrd\")\n",
    "SB2011_top1400=pd.read_excel(\"C:/Users/alexi/OneDrive/Bureau/Fac/Master/Mémoire/Analyse de données/Excel commission européenne/SB2011.xls\", engine=\"xlrd\")\n",
    "\n",
    "\n",
    "#longueur des listes d'entreprises tech par scoreboard\n",
    "df2024= SB2024_top2000[SB2024_top2000[\"Sector\"] == \"Software & Computer Services\"]\n",
    "print(\"Année 2024:\", len(df2024))\n",
    "df2023= SB2023_World2500[SB2023_World2500[\"Industry\"] == \"Software & Computer Services\"]\n",
    "print(\"Année 2023:\", len(df2023))\n",
    "df2022= SB2022_World2500[SB2022_World2500[\"Industry-ICB3 sector name\"] == \"Software & Computer Services\"]\n",
    "print(\"Année 2022:\", len(df2022))\n",
    "df2021= SB2021_World2500[SB2021_World2500[\"Industry-ICB3 sector name\"] == \"Software & Computer Services\"]\n",
    "print(\"Année 2021:\", len(df2021))\n",
    "df2020= SB2020_World2500[SB2020_World2500[\"Industry\"] == \"Software & Computer Services\"]\n",
    "print(\"Année 2020:\", len(df2020))\n",
    "df2019= SB2019_top2500[SB2019_top2500[\"Industry\"] == \"Software & Computer Services\"]\n",
    "print(\"Année 2019:\", len(df2019))\n",
    "df2018= SB2018_top2500[SB2018_top2500[\"Industry\"] == \"Software & Computer Services\"]\n",
    "print(\"Année 2018:\", len(df2018))\n",
    "df2017= SB2017_top2500[SB2017_top2500[\"Industry\"] == \"Software & Computer Services\"]\n",
    "print(\"Année 2017:\", len(df2017))\n",
    "df2016= SB2016_top2500[SB2016_top2500[\"Unnamed: 3\"] == \"Software & Computer Services\"]\n",
    "print(\"Année 2016:\", len(df2016))\n",
    "df2015= SB2015_top2500[SB2015_top2500[\"Unnamed: 3\"] == \"Software & Computer Services\"]\n",
    "print(\"Année 2015:\", len(df2015))\n",
    "df2014= SB2014_top2500[SB2014_top2500[\"Unnamed: 3\"] == \"Software & Computer Services\"]\n",
    "print(\"Année 2014:\", len(df2014))\n",
    "df2013= SB2013_top2000[SB2013_top2000[\"Unnamed: 3\"] == \"Software & Computer Services\"]\n",
    "print(\"Année 2013:\", len(df2013))\n",
    "df2012= SB2012_top1500[SB2012_top1500[\"Industry\"] == \"Software & computer services\"]\n",
    "print(\"Année 2012:\", len(df2012))\n",
    "\n",
    "\n",
    "\n",
    "#liste des entreprises qui sont présentes dans tous les scoreboards\n",
    "#colonne_entreprise=[\"Company\",\"Company\",\"Company\",\"Company\",\"Company\",\"Company\",\"Company\",\"Company\",\"Unnamed: 1\",\"Unnamed: 1\",\"World - 2500 companies ranked by R&D\",\"World - 2000 companies ranked by R&D\",\"Company\"]\n",
    "#liste_entreprise=[df2024, df2023, df2022, df2021, df2020, df2019, df2018, df2017, df2016, df2015, df2014, df2013, df2012]\n",
    "#ensembles = [set(df[col].str.strip().str.lower()) for df, col in zip(liste_entreprise, colonne_entreprise)]\n",
    "#communes = set.intersection(*ensembles)\n",
    "#print(\"Entreprises présentes dans toutes les listes :\")\n",
    "#print(communes)\n",
    "#len(communes)\n",
    "#df2012=54 entreprises\n",
    "#df2013=70 entreprises\n",
    "#df2014=96 entreprises\n",
    "#df2015=109 entreprises\n",
    "'''\n",
    "#choix des listes des entreprises en fonction du temps #arbitrage entre le nombre d'année(meilleure analyse temporelle) et le nombre d'entreprise (meilleure robustesse transversale) \n",
    "colonne_entreprise=[\"Company\",\"Company\",\"Company\",\"Company\",\"Company\",\"Company\",\"Company\",\"Company\",\"Unnamed: 1\",\"Unnamed: 1\"]\n",
    "liste_entreprise=[df2024, df2023, df2022, df2021, df2020, df2019, df2018, df2017, df2016, df2015]\n",
    "ensembles = [set(df[col].str.strip().str.lower()) for df, col in zip(liste_entreprise, colonne_entreprise)]\n",
    "communes = set.intersection(*ensembles)\n",
    "print(\"Entreprises présentes dans toutes les listes :\")\n",
    "print(communes)\n",
    "len(communes)\n",
    "'''\n",
    "\n",
    "\n",
    "#Harmonisation du nom des colonnes \n",
    "noms_harmonisés={\n",
    "    2012:{\"Company\":\"Entreprise\",\"R&D-2011\":\"R&D\",\"Sales-2011\":\"CA\",\"Capex-2011\":\"Capex\",\"Employees-2011\":\"Employés\"},\n",
    "    2013:{\"World - 2000 companies ranked by R&D\":\"Entreprise\",\" R&D 2012\":\"R&D\",\"Sales 2012\":\"CA\",\"Capex 2012\":\"Capex\",\"Employees 2012\":\"Employés\"},\n",
    "    2014:{\"World - 2500 companies ranked by R&D\":\"Entreprise\",\" R&D 2013 (€million)\":\"R&D\",\"Sales 2013 (€million)\":\"CA\",\"Capex 2013 (€million)\":\"Capex\",\"Employees 2013\":\"Employés\"},\n",
    "    2015:{\"Unnamed: 1\":\"Entreprise\",\"Unnamed: 4\":\"R&D\",\"Unnamed: 7\":\"CA\",\"Unnamed: 11\":\"Capex\",\"Unnamed: 19\":\"Employés\"}, \n",
    "    2016:{\"Unnamed: 1\":\"Entreprise\",\"Unnamed: 4\":\"R&D\",\"Unnamed: 7\":\"CA\",\"Unnamed: 11\":\"Capex\",\"Unnamed: 19\":\"Employés\"},\n",
    "    2017:{\"Company\":\"Entreprise\",\"R&D 2016/17 (€million)\":\"R&D\",\"Net sales (€million)\":\"CA\",\"Capex (€million)\":\"Capex\",\"Employees (th)\":\"Employés\"},\n",
    "    2018:{\"Company\":\"Entreprise\",\"R&D 2017/18 (€mn)\":\"R&D\",\"Net sales (€mn)\":\"CA\",\"Capex (€mn)\":\"Capex\",\"Employees\":\"Employés\"},\n",
    "    2019:{\"Company\":\"Entreprise\",\"R&D 2018/19 (€million)\":\"R&D\",\"Net sales (€million)\":\"CA\",\"Capex (€million)\":\"Capex\",\"Employees\":\"Employés\"},\n",
    "    2020:{\"Company\":\"Entreprise\",\"R&D 2019 (€million)\":\"R&D\",\"Net sales (€million)\":\"CA\",\"Capex (€million)\":\"Capex\",\"Employees\":\"Employés\"},\n",
    "    2021:{\"Company\":\"Entreprise\",\"R&D 2020 (€million)\":\"R&D\",\"Net sales (€million)\":\"CA\",\"Capex (€million)\":\"Capex\",\"Employees\":\"Employés\"},\n",
    "    2022:{\"Company\":\"Entreprise\",\"R&D 2021 (€million)\":\"R&D\",\"Net sales (€million)\":\"CA\",\"Capex (€million)\":\"Capex\",\"Employees\":\"Employés\"},\n",
    "    2023:{\"Company\":\"Entreprise\",\"R&D (€ million)\":\"R&D\",\"Net sales (€ million)\":\"CA\",\"Capex (€ million)\":\"Capex\",\"Employees\":\"Employés\"},\n",
    "    2024:{\"Company\":\"Entreprise\",\"R&D (€ million)\":\"R&D\",\"Net sales (€ million)\":\"CA\",\"Capex (€ million)\":\"Capex\",\"Employees\":\"Employés\"}\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d9893b2-e83b-4d5f-becf-46cb551fc8d8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Entreprises présentes de 2012 à 2024 : 42 entreprises\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['R&D', 'CA', 'Capex', 'Employés'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 58\u001b[0m\n\u001b[0;32m     56\u001b[0m     df \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEntreprise\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39misin(entreprises_communes)]\n\u001b[0;32m     57\u001b[0m     df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnnée\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m annee\n\u001b[1;32m---> 58\u001b[0m     df \u001b[38;5;241m=\u001b[39m df[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEntreprise\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mR&D\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCA\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCapex\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmployés\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnnée\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[0;32m     59\u001b[0m     dfs\u001b[38;5;241m.\u001b[39mappend(df)\n\u001b[0;32m     61\u001b[0m base_finale_1 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(dfs, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\web\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\web\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\web\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['R&D', 'CA', 'Capex', 'Employés'] not in index\""
     ]
    }
   ],
   "source": [
    "#créatin de la base de donnée, base_finale_1 (ajout des employés) \n",
    "# 1. 📂 Chargement des fichiers dans un dictionnaire\n",
    "fichiers = {\n",
    "    2024: SB2024_top2000,\n",
    "    2023: SB2023_World2500,\n",
    "    2022: SB2022_World2500,\n",
    "    2021: SB2021_World2500,\n",
    "    2020: SB2020_World2500,\n",
    "    2019: SB2019_top2500,\n",
    "    2018: SB2018_top2500,\n",
    "    2017: SB2017_top2500,\n",
    "    2016: SB2016_top2500,\n",
    "    2015: SB2015_top2500,\n",
    "    2014: SB2014_top2500,\n",
    "    2013: SB2013_top2000,\n",
    "    2012: SB2012_top1500,\n",
    "}\n",
    "\n",
    "# 2. 🧬 Colonnes de filtre par année (industry/tech)\n",
    "filtre_tech = {\n",
    "    2024: (\"Sector\", \"Software & Computer Services\"),\n",
    "    2023: (\"Industry\", \"Software & Computer Services\"),\n",
    "    2022: (\"Industry-ICB3 sector name\", \"Software & Computer Services\"),\n",
    "    2021: (\"Industry-ICB3 sector name\", \"Software & Computer Services\"),\n",
    "    2020: (\"Industry\", \"Software & Computer Services\"),\n",
    "    2019: (\"Industry\", \"Software & Computer Services\"),\n",
    "    2018: (\"Industry\", \"Software & Computer Services\"),\n",
    "    2017: (\"Industry\", \"Software & Computer Services\"),\n",
    "    2016: (\"Unnamed: 3\", \"Software & Computer Services\"),\n",
    "    2015: (\"Unnamed: 3\", \"Software & Computer Services\"),\n",
    "    2014: (\"Unnamed: 3\", \"Software & Computer Services\"),\n",
    "    2013: (\"Unnamed: 3\", \"Software & Computer Services\"),\n",
    "    2012: (\"Industry\", \"Software & computer services\")\n",
    "}\n",
    "\n",
    "\n",
    "# 4. 🔎 Identifier les entreprises communes sur la période\n",
    "entreprises_annee = []\n",
    "\n",
    "for annee, df in fichiers.items():\n",
    "    col_filtre, valeur = filtre_tech[annee]\n",
    "    col_entreprise = list(noms_harmonisés[annee].keys())[0]  # première clé = colonne entreprise\n",
    "    df_filtré = df[df[col_filtre] == valeur]\n",
    "    noms = df_filtré[col_entreprise].dropna().str.strip().str.lower().unique()\n",
    "    entreprises_annee.append(set(noms))\n",
    "\n",
    "entreprises_communes = set.intersection(*entreprises_annee)\n",
    "print(f\"📊 Entreprises présentes de 2012 à 2024 : {len(entreprises_communes)} entreprises\")\n",
    "\n",
    "# 5. 🧱 Construction de la base harmonisée\n",
    "dfs = []\n",
    "\n",
    "for annee, df in fichiers.items():\n",
    "    df = df.rename(columns=noms_harmonisés[annee])\n",
    "    df[\"Entreprise\"] = df[\"Entreprise\"].str.strip()\n",
    "    df = df[df[\"Entreprise\"].str.lower().isin(entreprises_communes)]\n",
    "    df[\"Année\"] = annee\n",
    "    df = df[[\"Entreprise\", \"R&D\", \"CA\", \"Capex\", \"Employés\", \"Année\"]]\n",
    "    dfs.append(df)\n",
    "\n",
    "base_finale_1 = pd.concat(dfs, ignore_index=True)\n",
    "print(f\"\\n✅ Base finale_1 : {base_finale_1.shape[0]} lignes, {base_finale_1.shape[1]} colonnes\")\n",
    "base_finale_1.to_csv(\"base_finale_1.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a402e6f-95d1-4004-8a48-550cab43e395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Entreprises présentes de 2012 à 2024 : 42 entreprises\n",
      "\n",
      "✅ Base finale_1 : 3503 lignes × 6 colonnes\n"
     ]
    }
   ],
   "source": [
    "#correction cellule précédente \n",
    "# 🏗️ Création de la base de données : base_finale_1 (ajout des employés)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# 1. 📂 Chargement des fichiers dans un dictionnaire\n",
    "fichiers = {\n",
    "    2024: SB2024_top2000,\n",
    "    2023: SB2023_World2500,\n",
    "    2022: SB2022_World2500,\n",
    "    2021: SB2021_World2500,\n",
    "    2020: SB2020_World2500,\n",
    "    2019: SB2019_top2500,\n",
    "    2018: SB2018_top2500,\n",
    "    2017: SB2017_top2500,\n",
    "    2016: SB2016_top2500,\n",
    "    2015: SB2015_top2500,\n",
    "    2014: SB2014_top2500,\n",
    "    2013: SB2013_top2000,\n",
    "    2012: SB2012_top1500,\n",
    "}\n",
    "\n",
    "# 2. 🧬 Colonnes de filtre (logiciel & services informatiques)\n",
    "filtre_tech = {\n",
    "    2024: (\"Sector\", \"Software & Computer Services\"),\n",
    "    2023: (\"Industry\", \"Software & Computer Services\"),\n",
    "    2022: (\"Industry-ICB3 sector name\", \"Software & Computer Services\"),\n",
    "    2021: (\"Industry-ICB3 sector name\", \"Software & Computer Services\"),\n",
    "    2020: (\"Industry\", \"Software & Computer Services\"),\n",
    "    2019: (\"Industry\", \"Software & Computer Services\"),\n",
    "    2018: (\"Industry\", \"Software & Computer Services\"),\n",
    "    2017: (\"Industry\", \"Software & Computer Services\"),\n",
    "    2016: (\"Unnamed: 3\", \"Software & Computer Services\"),\n",
    "    2015: (\"Unnamed: 3\", \"Software & Computer Services\"),\n",
    "    2014: (\"Unnamed: 3\", \"Software & Computer Services\"),\n",
    "    2013: (\"Unnamed: 3\", \"Software & Computer Services\"),\n",
    "    2012: (\"Industry\", \"Software & computer services\"),  # casse corrigée\n",
    "}\n",
    "\n",
    "# 3. ⚙️ Vérification préalable : présence de noms_harmonisés\n",
    "# Exemple de structure attendue pour noms_harmonisés :\n",
    "# noms_harmonisés = {\n",
    "#     2024: {\"Company\": \"Entreprise\", \"R&D spend\": \"R&D\", \"Sales\": \"CA\", \"Capex\": \"Capex\", \"Employees\": \"Employés\"},\n",
    "#     ...\n",
    "# }\n",
    "\n",
    "# 4. 🔎 Identifier les entreprises communes sur la période\n",
    "entreprises_annee = []\n",
    "\n",
    "for annee, df in fichiers.items():\n",
    "    col_filtre, valeur = filtre_tech[annee]\n",
    "    \n",
    "    # Vérification existence colonne de filtre\n",
    "    if col_filtre not in df.columns:\n",
    "        print(f\"⚠️ Colonne {col_filtre} absente dans le fichier {annee}\")\n",
    "        continue\n",
    "\n",
    "    # Récupère la colonne d'entreprise après harmonisation\n",
    "    col_entreprise = list(noms_harmonisés[annee].keys())[0]  # première clé = colonne entreprise\n",
    "\n",
    "    df_filtré = df[df[col_filtre].astype(str).str.strip().str.lower() == valeur.lower()]\n",
    "    \n",
    "    if col_entreprise not in df_filtré.columns:\n",
    "        print(f\"⚠️ Colonne entreprise {col_entreprise} absente dans {annee}\")\n",
    "        continue\n",
    "\n",
    "    noms = df_filtré[col_entreprise].dropna().astype(str).str.strip().str.lower().unique()\n",
    "    entreprises_annee.append(set(noms))\n",
    "\n",
    "# Intersect uniquement si au moins un set\n",
    "if entreprises_annee:\n",
    "    entreprises_communes = set.intersection(*entreprises_annee)\n",
    "    print(f\"📊 Entreprises présentes de 2012 à 2024 : {len(entreprises_communes)} entreprises\")\n",
    "else:\n",
    "    entreprises_communes = set()\n",
    "    print(\"⚠️ Aucune entreprise trouvée dans les fichiers\")\n",
    "\n",
    "# 5. 🧱 Construction de la base harmonisée (toutes entreprises du secteur Software & Computer Services)\n",
    "dfs = []\n",
    "\n",
    "for annee, df in fichiers.items():\n",
    "    col_filtre, valeur = filtre_tech[annee]\n",
    "\n",
    "    # Vérification de l’existence de la colonne de filtre\n",
    "    if col_filtre not in df.columns:\n",
    "        print(f\"⚠️ Colonne '{col_filtre}' absente dans le fichier {annee}\")\n",
    "        continue\n",
    "\n",
    "    # Récupère la colonne d’entreprise après harmonisation\n",
    "    mapping = noms_harmonisés.get(annee, {})\n",
    "    col_entreprise = next((k for k, v in mapping.items() if v == \"Entreprise\"), None)\n",
    "    \n",
    "    if col_entreprise is None or col_entreprise not in df.columns:\n",
    "        print(f\"⚠️ Colonne entreprise absente dans le fichier {annee}\")\n",
    "        continue\n",
    "\n",
    "    # Filtrage par secteur\n",
    "    df_filtré = df[df[col_filtre].astype(str).str.strip().str.lower() == valeur.lower()]\n",
    "\n",
    "    # Renommer les colonnes selon le dictionnaire harmonisé\n",
    "    df_filtré = df_filtré.rename(columns=noms_harmonisés[annee])\n",
    "    df_filtré = df_filtré.loc[:, ~df_filtré.columns.duplicated()]\n",
    "\n",
    "    if \"Entreprise\" not in df_filtré.columns:\n",
    "        print(f\"⚠️ Pas de colonne 'Entreprise' après renommage dans {annee}\")\n",
    "        continue\n",
    "\n",
    "    # Nettoyage noms d'entreprises\n",
    "    df_filtré[\"Entreprise\"] = df_filtré[\"Entreprise\"].astype(str).str.strip()\n",
    "    df_filtré[\"Année\"] = annee\n",
    "\n",
    "    # Gestion des colonnes manquantes\n",
    "    for col in [\"R&D\", \"CA\", \"Capex\", \"Employés\"]:\n",
    "        if col not in df_filtré.columns:\n",
    "            df_filtré[col] = pd.NA\n",
    "\n",
    "    # Sélection des colonnes finales\n",
    "    try:\n",
    "        df_filtré = df_filtré[[\"Entreprise\", \"R&D\", \"CA\", \"Capex\", \"Employés\", \"Année\"]]\n",
    "    except KeyError as e:\n",
    "        print(f\"⚠️ Colonnes manquantes dans {annee}: {e}\")\n",
    "        continue\n",
    "\n",
    "    dfs.append(df_filtré)\n",
    "\n",
    "# Concaténation finale\n",
    "if dfs:\n",
    "    base_finale_1 = pd.concat(dfs, ignore_index=True)\n",
    "    print(f\"\\n✅ Base finale_1 : {base_finale_1.shape[0]} lignes × {base_finale_1.shape[1]} colonnes\")\n",
    "    base_finale_1.to_csv(\"base_finale_1.csv\", index=False)\n",
    "else:\n",
    "    print(\"⚠️ Aucun DataFrame n’a pu être concaténé.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aae6baef-4cce-49c5-a109-8fe863d7beaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📅 Adobe est présente dans les années : [2019, 2020, 2021, 2022, 2023, 2024]\n"
     ]
    }
   ],
   "source": [
    "# 🔍 Filtrer les années où Adobe est présente\n",
    "adobe_annees = base_finale_1[base_finale_1[\"Entreprise\"].str.lower() == \"adobe\"][\"Année\"].unique()\n",
    "adobe_annees = sorted(adobe_annees)\n",
    "\n",
    "print(f\"📅 Adobe est présente dans les années : {adobe_annees}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "a1ddcbe8-7148-498c-a924-d0c07c434336",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Année Free Cash Flow (Millions USD)\n",
      "9   2015                      4,922.01\n",
      "8   2016                      6,130.20\n",
      "7   2017                      5,096.40\n",
      "6   2018                      5,350.43\n",
      "5   2019                      5,674.31\n",
      "4   2020                      7,067.58\n",
      "3   2021                      7,742.60\n",
      "2   2022                      9,450.53\n",
      "1   2023                     12,066.41\n",
      "0   2024                     10,701.58\n"
     ]
    }
   ],
   "source": [
    "#test de scrapping sur macrotrends \n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Configuration de Selenium en mode headless (sans ouvrir le navigateur)\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "# Accès à la page Macrotrends de Novo Nordisk\n",
    "url = \"https://www.macrotrends.net/stocks/charts/NVO/novo-nordisk/free-cash-flow\"\n",
    "driver.get(url)\n",
    "time.sleep(5)  # Attente du chargement dynamique\n",
    "\n",
    "# Analyse du contenu de la page\n",
    "soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "driver.quit()\n",
    "\n",
    "# Recherche de la table de données\n",
    "table = soup.find(\"table\", {\"class\": \"historical_data_table table\"})\n",
    "\n",
    "# Extraction des lignes valides\n",
    "data = []\n",
    "if table:\n",
    "    rows = table.find_all(\"tr\")\n",
    "    for row in rows[1:]:  # Ignorer l'en-tête\n",
    "        cols = row.find_all(\"td\")\n",
    "        if len(cols) == 2:\n",
    "            year = cols[0].text.strip()\n",
    "            fcf = cols[1].text.strip()\n",
    "            if year.isdigit() and 2015 <= int(year) <= 2024:\n",
    "                data.append({\"Année\": int(year), \"Free Cash Flow (Millions USD)\": fcf})\n",
    "else:\n",
    "    print(\" Aucune table de données trouvée.\")\n",
    "\n",
    "# Conversion en DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "df = df.sort_values(by=\"Année\")  # Tri chronologique\n",
    "\n",
    "# Affichage ou export\n",
    "print(df)\n",
    "# df.to_csv(\"novo_nordisk_fcf_2015_2024.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "de1c72d6-6f09-4982-a451-a7c74d90a4f1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Scraping FCF pour gilead sciences...\n",
      "🔍 Scraping FCF pour esperion therapeutics...\n",
      "🔍 Scraping FCF pour karyopharm therapeutics...\n",
      "🔍 Scraping FCF pour guerbet...\n",
      "❌ Table non trouvée pour guerbet\n",
      "🔍 Scraping FCF pour opko health...\n",
      "🔍 Scraping FCF pour astellas pharma...\n",
      "🔍 Scraping FCF pour amgen...\n",
      "🔍 Scraping FCF pour lupin...\n",
      "🔍 Scraping FCF pour servier...\n",
      "🔍 Scraping FCF pour mallinckrodt...\n",
      "❌ Table non trouvée pour mallinckrodt\n",
      "🔍 Scraping FCF pour almirall...\n",
      "❌ Table non trouvée pour almirall\n",
      "🔍 Scraping FCF pour richter gedeon...\n",
      "❌ Table non trouvée pour richter gedeon\n",
      "🔍 Scraping FCF pour santen pharmaceutical...\n",
      "❌ Table non trouvée pour santen pharmaceutical\n",
      "🔍 Scraping FCF pour biomarin pharmaceutical...\n",
      "❌ Table non trouvée pour biomarin pharmaceutical\n",
      "🔍 Scraping FCF pour uniqure...\n",
      "🔍 Scraping FCF pour tg therapeutics...\n",
      "🔍 Scraping FCF pour eli lilly...\n",
      "🔍 Scraping FCF pour endo international...\n",
      "❌ Table non trouvée pour endo international\n",
      "🔍 Scraping FCF pour chiesi farmaceutici...\n",
      "🔍 Scraping FCF pour incyte...\n",
      "🔍 Scraping FCF pour fosun international...\n",
      "🔍 Scraping FCF pour sanofi...\n",
      "🔍 Scraping FCF pour towa pharmaceutical...\n",
      "❌ Table non trouvée pour towa pharmaceutical\n",
      "🔍 Scraping FCF pour exelixis...\n",
      "🔍 Scraping FCF pour qiagen...\n",
      "🔍 Scraping FCF pour coherus biosciences...\n",
      "🔍 Scraping FCF pour ultragenyx pharmaceutical...\n",
      "🔍 Scraping FCF pour kaken pharmaceutical...\n",
      "❌ Table non trouvée pour kaken pharmaceutical\n",
      "🔍 Scraping FCF pour abbvie...\n",
      "🔍 Scraping FCF pour mochida pharmaceutical...\n",
      "🔍 Scraping FCF pour omeros...\n",
      "🔍 Scraping FCF pour basilea pharmaceutica...\n",
      "❌ Table non trouvée pour basilea pharmaceutica\n",
      "🔍 Scraping FCF pour bio-techne...\n",
      "❌ Table non trouvée pour bio-techne\n",
      "🔍 Scraping FCF pour sichuan kelun pharmaceutical...\n",
      "❌ Table non trouvée pour sichuan kelun pharmaceutical\n",
      "🔍 Scraping FCF pour swedish orphan biovitrum...\n",
      "❌ Table non trouvée pour swedish orphan biovitrum\n",
      "🔍 Scraping FCF pour alnylam pharmaceuticals...\n",
      "🔍 Scraping FCF pour alk abello...\n",
      "❌ Table non trouvée pour alk abello\n",
      "🔍 Scraping FCF pour jazz pharmaceuticals...\n",
      "🔍 Scraping FCF pour sarepta therapeutics...\n",
      "🔍 Scraping FCF pour alkermes...\n",
      "🔍 Scraping FCF pour sage therapeutics...\n",
      "🔍 Scraping FCF pour novozymes...\n",
      "🔍 Scraping FCF pour insmed...\n",
      "🔍 Scraping FCF pour jiangsu kanion pharmaceutical...\n",
      "❌ Table non trouvée pour jiangsu kanion pharmaceutical\n",
      "🔍 Scraping FCF pour pfizer...\n",
      "🔍 Scraping FCF pour rohto pharmaceutical...\n",
      "❌ Table non trouvée pour rohto pharmaceutical\n",
      "🔍 Scraping FCF pour perrigo...\n",
      "🔍 Scraping FCF pour morphosys...\n",
      "❌ Table non trouvée pour morphosys\n",
      "🔍 Scraping FCF pour bavarian nordic...\n",
      "❌ Table non trouvée pour bavarian nordic\n",
      "🔍 Scraping FCF pour hikma pharmaceuticals...\n",
      "❌ Table non trouvée pour hikma pharmaceuticals\n",
      "🔍 Scraping FCF pour novo nordisk...\n",
      "🔍 Scraping FCF pour luye pharma...\n",
      "❌ Table non trouvée pour luye pharma\n",
      "🔍 Scraping FCF pour livzon pharmaceutical...\n",
      "❌ Table non trouvée pour livzon pharmaceutical\n",
      "🔍 Scraping FCF pour acadia pharmaceuticals...\n",
      "🔍 Scraping FCF pour novavax...\n",
      "🔍 Scraping FCF pour illumina...\n",
      "🔍 Scraping FCF pour recordati...\n",
      "🔍 Scraping FCF pour ono pharmaceutical...\n",
      "❌ Table non trouvée pour ono pharmaceutical\n",
      "🔍 Scraping FCF pour zoetis...\n",
      "🔍 Scraping FCF pour genus...\n",
      "❌ Table non trouvée pour genus\n",
      "🔍 Scraping FCF pour celltrion...\n",
      "❌ Table non trouvée pour celltrion\n",
      "🔍 Scraping FCF pour sino biopharmaceutical...\n",
      "❌ Table non trouvée pour sino biopharmaceutical\n",
      "🔍 Scraping FCF pour tasly pharmaceutical...\n",
      "❌ Table non trouvée pour tasly pharmaceutical\n",
      "🔍 Scraping FCF pour dr reddy's laboratories...\n",
      "❌ Table non trouvée pour dr reddy's laboratories\n",
      "🔍 Scraping FCF pour csl...\n",
      "❌ Table non trouvée pour csl\n",
      "🔍 Scraping FCF pour novartis...\n",
      "❌ Table non trouvée pour novartis\n",
      "🔍 Scraping FCF pour fibrogen...\n",
      "🔍 Scraping FCF pour oxford nanopore technologies...\n",
      "❌ Table non trouvée pour oxford nanopore technologies\n",
      "🔍 Scraping FCF pour diasorin...\n",
      "❌ Table non trouvée pour diasorin\n",
      "🔍 Scraping FCF pour biocryst pharmaceuticals...\n",
      "🔍 Scraping FCF pour shionogi...\n",
      "❌ Table non trouvée pour shionogi\n",
      "🔍 Scraping FCF pour ipsen...\n",
      "❌ Table non trouvée pour ipsen\n",
      "🔍 Scraping FCF pour green cross holdings...\n",
      "🔍 Scraping FCF pour bluebird bio...\n",
      "🔍 Scraping FCF pour bristol-myers squibb...\n",
      "🔍 Scraping FCF pour daiichi sankyo...\n",
      "🔍 Scraping FCF pour huadong medicine...\n",
      "❌ Table non trouvée pour huadong medicine\n",
      "🔍 Scraping FCF pour orion oyj...\n",
      "❌ Table non trouvée pour orion oyj\n",
      "🔍 Scraping FCF pour johnson & johnson...\n",
      "❌ Table non trouvée pour johnson & johnson\n",
      "🔍 Scraping FCF pour merck de...\n",
      "❌ Table non trouvée pour merck de\n",
      "🔍 Scraping FCF pour cipla...\n",
      "❌ Table non trouvée pour cipla\n",
      "🔍 Scraping FCF pour sun pharmaceutical industries...\n",
      "❌ Table non trouvée pour sun pharmaceutical industries\n",
      "🔍 Scraping FCF pour h lundbeck...\n",
      "❌ Table non trouvée pour h lundbeck\n",
      "🔍 Scraping FCF pour united therapeutics...\n",
      "🔍 Scraping FCF pour amicus therapeutics...\n",
      "🔍 Scraping FCF pour hanmi pharm...\n",
      "❌ Table non trouvée pour hanmi pharm\n",
      "🔍 Scraping FCF pour glenmark pharmaceuticals...\n",
      "❌ Table non trouvée pour glenmark pharmaceuticals\n",
      "🔍 Scraping FCF pour cspc pharmaceutical...\n",
      "❌ Table non trouvée pour cspc pharmaceutical\n",
      "🔍 Scraping FCF pour zhejiang medicine...\n",
      "❌ Table non trouvée pour zhejiang medicine\n",
      "🔍 Scraping FCF pour bayer...\n",
      "❌ Table non trouvée pour bayer\n",
      "🔍 Scraping FCF pour nippon shinyaku...\n",
      "❌ Table non trouvée pour nippon shinyaku\n",
      "🔍 Scraping FCF pour chong kun dang pharmaceutical...\n",
      "❌ Table non trouvée pour chong kun dang pharmaceutical\n",
      "🔍 Scraping FCF pour revance therapeutics...\n",
      "❌ Table non trouvée pour revance therapeutics\n",
      "🔍 Scraping FCF pour otsuka...\n",
      "❌ Table non trouvée pour otsuka\n",
      "🔍 Scraping FCF pour shijiazhuang yiling pharmaceutical...\n",
      "❌ Table non trouvée pour shijiazhuang yiling pharmaceutical\n",
      "🔍 Scraping FCF pour ucb...\n",
      "❌ Table non trouvée pour ucb\n",
      "🔍 Scraping FCF pour neurocrine biosciences...\n",
      "🔍 Scraping FCF pour merck us...\n",
      "❌ Table non trouvée pour merck us\n",
      "🔍 Scraping FCF pour roche...\n",
      "❌ Table non trouvée pour roche\n",
      "🔍 Scraping FCF pour agios pharmaceuticals...\n",
      "🔍 Scraping FCF pour yuhan...\n",
      "❌ Table non trouvée pour yuhan\n",
      "🔍 Scraping FCF pour grifols...\n",
      "❌ Table non trouvée pour grifols\n",
      "🔍 Scraping FCF pour vertex pharmaceuticals...\n",
      "🔍 Scraping FCF pour nektar therapeutics...\n",
      "🔍 Scraping FCF pour humanwell healthcare...\n",
      "🔍 Scraping FCF pour ptc therapeutics...\n",
      "🔍 Scraping FCF pour blue print medicines...\n",
      "❌ Table non trouvée pour blue print medicines\n",
      "🔍 Scraping FCF pour astrazeneca...\n",
      "🔍 Scraping FCF pour krka...\n",
      "❌ Table non trouvée pour krka\n",
      "    Entreprise  Année Free Cash Flow (Millions USD)\n",
      "0       Abbvie   2015                      7,003.00\n",
      "1       Abbvie   2016                      6,562.00\n",
      "2       Abbvie   2017                      9,431.00\n",
      "3       Abbvie   2018                     12,789.00\n",
      "4       Abbvie   2019                     12,772.00\n",
      "..         ...    ...                           ...\n",
      "416     Zoetis   2020                      1,694.00\n",
      "417     Zoetis   2021                      1,738.00\n",
      "418     Zoetis   2022                      1,327.00\n",
      "419     Zoetis   2023                      1,625.00\n",
      "420     Zoetis   2024                      2,299.00\n",
      "\n",
      "[421 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#scrapping généralisé sur macrotrends \n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "\n",
    "# Initialisation du DataFrame final\n",
    "fcf_all = pd.DataFrame()\n",
    "\n",
    "# Configuration du navigateur headless\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "# Boucle sur chaque entreprise\n",
    "for entreprise, ticker in entreprise_ticker.items():\n",
    "    print(f\" Scraping FCF pour {entreprise}...\")\n",
    "\n",
    "    # Format du nom dans l'URL (espaces → tirets)\n",
    "    nom_url = entreprise.lower().replace(\" \", \"-\")\n",
    "    url = f\"https://www.macrotrends.net/stocks/charts/{ticker}/{nom_url}/free-cash-flow\"\n",
    "\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(5)  # temps pour chargement dynamique\n",
    "        soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "        table = soup.find(\"table\", {\"class\": \"historical_data_table table\"})\n",
    "\n",
    "        if not table:\n",
    "            print(f\" Table non trouvée pour {entreprise}\")\n",
    "            continue\n",
    "\n",
    "        rows = table.find_all(\"tr\")\n",
    "        for row in rows[1:]:\n",
    "            cols = row.find_all(\"td\")\n",
    "            if len(cols) == 2:\n",
    "                year = cols[0].text.strip()\n",
    "                fcf = cols[1].text.strip()\n",
    "                if year.isdigit() and 2015 <= int(year) <= 2024:\n",
    "                    fcf_all = pd.concat([\n",
    "                        fcf_all,\n",
    "                        pd.DataFrame([{\n",
    "                            \"Entreprise\": entreprise.title(),\n",
    "                            \"Année\": int(year),\n",
    "                            \"Free Cash Flow (Millions USD)\": fcf\n",
    "                        }])\n",
    "                    ])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\" Erreur pour {entreprise}: {e}\")\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "# Nettoyage final\n",
    "fcf_all = fcf_all.sort_values(by=[\"Entreprise\", \"Année\"]).reset_index(drop=True)\n",
    "\n",
    "# Affichage\n",
    "print(fcf_all)\n",
    "# fcf_all.to_csv(\"fcf_par_entreprise_2015_2024.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "5ea2d1f7-37ee-48f0-9e5e-d12c8d41f45d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur lors de la récupération des données pour LUPIN.NS\n",
      "Erreur lors de la récupération des données pour ALM.MC\n",
      "Erreur lors de la récupération des données pour 0656.HK\n",
      "Erreur lors de la récupération des données pour BSLN.SW\n",
      "Erreur lors de la récupération des données pour 002422.SZ\n",
      "Erreur lors de la récupération des données pour SOBI.ST\n",
      "Erreur lors de la récupération des données pour ALK-B.CO\n",
      "Erreur lors de la récupération des données pour NZYM-B.CO\n",
      "Erreur lors de la récupération des données pour 600557.SS\n",
      "Erreur lors de la récupération des données pour BAVA.CO\n",
      "Erreur lors de la récupération des données pour HIK.L\n",
      "Erreur lors de la récupération des données pour 2186.HK\n",
      "Erreur lors de la récupération des données pour 000513.SZ\n",
      "Erreur lors de la récupération des données pour REC.MI\n",
      "Erreur lors de la récupération des données pour GNS.L\n",
      "Erreur lors de la récupération des données pour 068270.KQ\n",
      "Erreur lors de la récupération des données pour 1177.HK\n",
      "Erreur lors de la récupération des données pour 600535.SS\n",
      "Erreur lors de la récupération des données pour CSL.AX\n",
      "Erreur lors de la récupération des données pour ONT.L\n",
      "Erreur lors de la récupération des données pour DIA.MI\n",
      "Erreur lors de la récupération des données pour IPN.PA\n",
      "Erreur lors de la récupération des données pour 000963.SZ\n",
      "Erreur lors de la récupération des données pour MRK.DE\n",
      "Erreur lors de la récupération des données pour CIPLA.NS\n",
      "Erreur lors de la récupération des données pour SUNPHARMA.NS\n",
      "Erreur lors de la récupération des données pour LUN.CO\n",
      "Erreur lors de la récupération des données pour 128940.KQ\n",
      "Erreur lors de la récupération des données pour GLENMARK.NS\n",
      "Erreur lors de la récupération des données pour 1093.HK\n",
      "Erreur lors de la récupération des données pour 600216.SS\n",
      "Erreur lors de la récupération des données pour BAYN.DE\n",
      "Erreur lors de la récupération des données pour 185750.KQ\n",
      "Erreur lors de la récupération des données pour 002603.SZ\n",
      "Erreur lors de la récupération des données pour UCB.BR\n",
      "Erreur lors de la récupération des données pour 000100.KQ\n",
      "Erreur lors de la récupération des données pour 600079.SS\n",
      "Erreur lors de la récupération des données pour KRKG.LJ\n",
      "    Entreprise        Date  Free Cash Flow\n",
      "0         GILD  2024-12-31     10305000000\n",
      "1         GILD  2023-12-31      7421000000\n",
      "2         GILD  2022-12-31      8344000000\n",
      "3         GILD  2021-12-31     10805000000\n",
      "4         GILD  2020-12-31      7518000000\n",
      "..         ...         ...             ...\n",
      "325        AZN  2024-12-31      7275000000\n",
      "326        AZN  2023-12-31      6567000000\n",
      "327        AZN  2022-12-31      7237000000\n",
      "328        AZN  2021-12-31      3763000000\n",
      "329        AZN  2020-12-31      2193000000\n",
      "\n",
      "[330 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#scrapping de données sur financial modeling prep\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Remplace par ta clé API personnelle\n",
    "API_KEY = 'oLPc2WtxwntnY3j9OhIXQwfbPE2FdlhW'\n",
    "\n",
    "# Liste pour stocker les données\n",
    "fcf_data = []\n",
    "\n",
    "for ticker in tickers:\n",
    "    url = f'https://financialmodelingprep.com/api/v3/cash-flow-statement/{ticker}?period=annual&limit=10&apikey={API_KEY}'\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        for entry in data:\n",
    "            fcf_data.append({\n",
    "                'Entreprise': ticker,\n",
    "                'Date': entry['date'],\n",
    "                'Free Cash Flow': entry.get('freeCashFlow', None)\n",
    "            })\n",
    "    else:\n",
    "        print(f'Erreur lors de la récupération des données pour {ticker}')\n",
    "\n",
    "# Convertir en DataFrame\n",
    "df_fcf = pd.DataFrame(fcf_data)\n",
    "\n",
    "# Afficher les données\n",
    "print(df_fcf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "37f9adb5-b7d7-45e9-a56a-7541cbd525c7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Récupération FCF pour gilead sciences (GILD)...\n",
      "Erreur pour GILD : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour esperion therapeutics (ESPR)...\n",
      "Erreur pour ESPR : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour karyopharm therapeutics (KPTI)...\n",
      "Erreur pour KPTI : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour guerbet (GBT)...\n",
      "Récupération FCF pour opko health (OPK)...\n",
      "Erreur pour OPK : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour astellas pharma (ALPMY)...\n",
      "Erreur pour ALPMY : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour amgen (AMGN)...\n",
      "Erreur pour AMGN : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour lupin (LUPIN.NS)...\n",
      "Erreur pour LUPIN.NS : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour mallinckrodt (MNK)...\n",
      "Récupération FCF pour almirall (ALM.MC)...\n",
      "Erreur pour ALM.MC : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour richter gedeon (RICHTER.BD)...\n",
      "Erreur pour RICHTER.BD : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour santen pharmaceutical (SANTF)...\n",
      "Récupération FCF pour biomarin pharmaceutical (BMRN)...\n",
      "Erreur pour BMRN : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour uniqure (QURE)...\n",
      "Erreur pour QURE : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour tg therapeutics (TGTX)...\n",
      "Erreur pour TGTX : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour eli lilly (LLY)...\n",
      "Erreur pour LLY : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour endo international (ENDPQ)...\n",
      "Récupération FCF pour incyte (INCY)...\n",
      "Erreur pour INCY : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour fosun international (0656.HK)...\n",
      "Erreur pour 0656.HK : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour sanofi (SNY)...\n",
      "Erreur pour SNY : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour towa pharmaceutical (4553.T)...\n",
      "Erreur pour 4553.T : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour exelixis (EXEL)...\n",
      "Erreur pour EXEL : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour qiagen (QGEN)...\n",
      "Erreur pour QGEN : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour coherus biosciences (CHRS)...\n",
      "Erreur pour CHRS : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour ultragenyx pharmaceutical (RARE)...\n",
      "Erreur pour RARE : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour kaken pharmaceutical (4521.T)...\n",
      "Erreur pour 4521.T : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour abbvie (ABBV)...\n",
      "Erreur pour ABBV : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour mochida pharmaceutical (4534.T)...\n",
      "Erreur pour 4534.T : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour omeros (OMER)...\n",
      "Erreur pour OMER : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour basilea pharmaceutica (BSLN.SW)...\n",
      "Erreur pour BSLN.SW : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour bio-techne (TECH)...\n",
      "Erreur pour TECH : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour sichuan kelun pharmaceutical (002422.SZ)...\n",
      "Erreur pour 002422.SZ : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour swedish orphan biovitrum (SOBI.ST)...\n",
      "Erreur pour SOBI.ST : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour alnylam pharmaceuticals (ALNY)...\n",
      "Erreur pour ALNY : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour alk abello (ALK-B.CO)...\n",
      "Erreur pour ALK-B.CO : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour jazz pharmaceuticals (JAZZ)...\n",
      "Erreur pour JAZZ : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour sarepta therapeutics (SRPT)...\n",
      "Erreur pour SRPT : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour alkermes (ALKS)...\n",
      "Erreur pour ALKS : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour sage therapeutics (SAGE)...\n",
      "Erreur pour SAGE : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour novozymes (NZYM-B.CO)...\n",
      "Récupération FCF pour insmed (INSM)...\n",
      "Erreur pour INSM : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour jiangsu kanion pharmaceutical (600557.SS)...\n",
      "Erreur pour 600557.SS : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour pfizer (PFE)...\n",
      "Erreur pour PFE : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour rohto pharmaceutical (4527.T)...\n",
      "Erreur pour 4527.T : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour perrigo (PRGO)...\n",
      "Erreur pour PRGO : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour morphosys (MOR)...\n",
      "Récupération FCF pour bavarian nordic (BAVA.CO)...\n",
      "Erreur pour BAVA.CO : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour hikma pharmaceuticals (HIK.L)...\n",
      "Erreur pour HIK.L : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour novo nordisk (NVO)...\n",
      "Erreur pour NVO : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour luye pharma (2186.HK)...\n",
      "Erreur pour 2186.HK : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour livzon pharmaceutical (000513.SZ)...\n",
      "Erreur pour 000513.SZ : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour acadia pharmaceuticals (ACAD)...\n",
      "Erreur pour ACAD : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour novavax (NVAX)...\n",
      "Erreur pour NVAX : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour illumina (ILMN)...\n",
      "Erreur pour ILMN : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour recordati (REC.MI)...\n",
      "Erreur pour REC.MI : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour ono pharmaceutical (4528.T)...\n",
      "Erreur pour 4528.T : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour zoetis (ZTS)...\n",
      "Erreur pour ZTS : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour genus (GNS.L)...\n",
      "Erreur pour GNS.L : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour celltrion (068270.KQ)...\n",
      "Erreur pour 068270.KQ : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour sino biopharmaceutical (1177.HK)...\n",
      "Erreur pour 1177.HK : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour tasly pharmaceutical (600535.SS)...\n",
      "Erreur pour 600535.SS : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour dr reddy's laboratories (RDY)...\n",
      "Erreur pour RDY : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour csl (CSL.AX)...\n",
      "Erreur pour CSL.AX : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour novartis (NVS)...\n",
      "Erreur pour NVS : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour fibrogen (FGEN)...\n",
      "Erreur pour FGEN : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour oxford nanopore technologies (ONT.L)...\n",
      "Erreur pour ONT.L : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour diasorin (DIA.MI)...\n",
      "Erreur pour DIA.MI : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour biocryst pharmaceuticals (BCRX)...\n",
      "Erreur pour BCRX : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour shionogi (4507.T)...\n",
      "Erreur pour 4507.T : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour ipsen (IPN.PA)...\n",
      "Erreur pour IPN.PA : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour bluebird bio (BLUE)...\n",
      "Erreur pour BLUE : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour bristol-myers squibb (BMY)...\n",
      "Erreur pour BMY : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour daiichi sankyo (4568.T)...\n",
      "Erreur pour 4568.T : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour huadong medicine (000963.SZ)...\n",
      "Erreur pour 000963.SZ : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour orion oyj (ORNBV.HE)...\n",
      "Erreur pour ORNBV.HE : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour johnson & johnson (JNJ)...\n",
      "Erreur pour JNJ : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour merck de (MRK.DE)...\n",
      "Erreur pour MRK.DE : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour cipla (CIPLA.NS)...\n",
      "Erreur pour CIPLA.NS : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour sun pharmaceutical industries (SUNPHARMA.NS)...\n",
      "Erreur pour SUNPHARMA.NS : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour h lundbeck (LUN.CO)...\n",
      "Récupération FCF pour united therapeutics (UTHR)...\n",
      "Erreur pour UTHR : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour amicus therapeutics (FOLD)...\n",
      "Erreur pour FOLD : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour hanmi pharm (128940.KQ)...\n",
      "Erreur pour 128940.KQ : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour glenmark pharmaceuticals (GLENMARK.NS)...\n",
      "Erreur pour GLENMARK.NS : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour cspc pharmaceutical (1093.HK)...\n",
      "Erreur pour 1093.HK : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour zhejiang medicine (600216.SS)...\n",
      "Erreur pour 600216.SS : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour bayer (BAYN.DE)...\n",
      "Erreur pour BAYN.DE : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour nippon shinyaku (4516.T)...\n",
      "Erreur pour 4516.T : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour chong kun dang pharmaceutical (185750.KQ)...\n",
      "Erreur pour 185750.KQ : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour revance therapeutics (RVNC)...\n",
      "Récupération FCF pour otsuka (4578.T)...\n",
      "Erreur pour 4578.T : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour shijiazhuang yiling pharmaceutical (002603.SZ)...\n",
      "Erreur pour 002603.SZ : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour ucb (UCB.BR)...\n",
      "Erreur pour UCB.BR : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour neurocrine biosciences (NBIX)...\n",
      "Erreur pour NBIX : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour merck us (MRK)...\n",
      "Erreur pour MRK : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour roche (RHHBY)...\n",
      "Erreur pour RHHBY : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour agios pharmaceuticals (AGIO)...\n",
      "Erreur pour AGIO : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour yuhan (000100.KQ)...\n",
      "Erreur pour 000100.KQ : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour grifols (GRFS)...\n",
      "Erreur pour GRFS : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour vertex pharmaceuticals (VRTX)...\n",
      "Erreur pour VRTX : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour nektar therapeutics (NKTR)...\n",
      "Erreur pour NKTR : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour humanwell healthcare (600079.SS)...\n",
      "Erreur pour 600079.SS : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour ptc therapeutics (PTCT)...\n",
      "Erreur pour PTCT : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour blue print medicines (BPMC)...\n",
      "Erreur pour BPMC : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour astrazeneca (AZN)...\n",
      "Erreur pour AZN : 'Total Cash From Operating Activities'\n",
      "Récupération FCF pour krka (KRKG.LJ)...\n",
      "Extraction terminée. Fichier sauvegardé : fcf_data_2015_2024.csv\n"
     ]
    }
   ],
   "source": [
    "#scrapping de données avec yfinance \n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "#Résultats stockés ici\n",
    "fcf_dict = {}\n",
    "\n",
    "#Fonction de récupération du FCF\n",
    "def get_fcf(ticker):\n",
    "    try:\n",
    "        data = yf.Ticker(ticker).cashflow\n",
    "        if data.empty:\n",
    "            return None\n",
    "        fcf = data.loc['Total Cash From Operating Activities'] - data.loc['Capital Expenditures']\n",
    "        return fcf\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur pour {ticker} : {e}\")\n",
    "        return None\n",
    "\n",
    "#Boucle sur les tickers\n",
    "for entreprise, ticker in entreprise_ticker.items():\n",
    "    if ticker:\n",
    "        fcf = get_fcf(ticker)\n",
    "        if fcf is not None:\n",
    "            fcf_filtered = fcf[[col for col in fcf.index if int(str(col)[:4]) in range(2015, 2025)]]\n",
    "            fcf_dict[entreprise] = fcf_filtered.to_dict()\n",
    "        else:\n",
    "            fcf_dict[entreprise] = None\n",
    "\n",
    "#Convertir en DataFrame pour exporter\n",
    "fcf_df = pd.DataFrame.from_dict(fcf_dict, orient='index')\n",
    "fcf_df.to_csv(\"fcf_data_2015_2024.csv\")\n",
    "\n",
    "print(\"Extraction terminée. Fichier sauvegardé : fcf_data_2015_2024.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
